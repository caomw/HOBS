Emerging head-worn computing devices can enable hands-free interactions with smart objects in physical spaces. 
%
We introduce and characterize a method for selecting and interacting with physical targets at a distance using head orientation. We augment a commercial wearable device, Google Glass, with an infrared (IR) emitter to select targets equipped with IR receivers. The fundamental imprecision of head orientation requires area selection techniques, which can lead to ambiguous selections. We introduce a two level disambiguation strategy: first, networked receivers use IR intensity sensors to estimate which target is the intended selection; second, users can fall back to a manual disambiguation technique using their near-eye display. The technique does not require an a priori map of target devices. However, a spatial data structure can be inferred to aid ordering of items during manual disambiguation.
%
A target acquisition study with 14 participants shows that selection using head orientation with our device outperforms list selection on a wearable device. Intensity-based target disambiguation reduces selection time and error rate in dense target environments. \bjoern{rewrite once we have results}. We implement this technique in an application for controlling smart appliances and report qualitative user impressions.