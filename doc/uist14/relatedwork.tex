%!TEX root = uist14.tex
\section{Background and Related Work}
\subsection{Head and Eye Input}
Head movement has long been used for virtual camera control in VR applications~\cite{pausch_user_1993} and as an assitive input technology for cursor control of desktop applications~\cite{}. Head joysticks have been evaluated using Fitts' law and \bjoern{what did they find?} However, 
Card, summarizing other work, shows that neck muscles are a poor muscle group for pointing in general: neck muscles only have a bandwidth of about $4.2bits/s$ (compared to $23bits/s$ of wrist muscles used by a standard mouse)~\cite{Card:1991:MAD:123078.128726}. 

Contrast: we're not working on GUI tasks, but on identifyign and selecting ubicomp objects in physical spaces.

Gaze control of existing graphical user intefaces~\cite{kumar2007eyepoint}. There are also wearable gaze trackers~\cite{SMI} -- but while these can provide a concrete point in space where a user is looking, turning this information into a selection information requires either a fixed absolute map of each space with known location and orientation of the user, or... Our system works through point-to-point IR communication and does not require any a priori knowledge of where objects are located.

Our work is closer in spirit to Selker's headworn system~\cite{Selker:2001:EGE:634067.634176}.

\subsection{Area Cursors}
A central hypothesis of this paper is that the area selection paradigm is well matched to head orientation input.
\bjoern{Need a discussion of area cursors~\cite{kabbash1995prince,worden1997making,Findlater-uist2010}.}

\subsection{Pointing in physical spaces}
\bjoern{take this from prior CHI submission.}

\bjoern{TODO: Add discussion of ~\cite{swindells_that_2002,merrill_augmenting_2007}.}
