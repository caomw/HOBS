\bjoern{I prefer to write the abstract {\em first}, not last, as a blueprint for the rest of the paper.}

Emerging head-worn computing devices can enable hands-free interactions in physical spaces. 
%
We introduce and characterize a method for selecting and interacting with physical targets at a distance using head orientation. We augment a commercial wearable device, Google Glass, with an infrared (IR) emitter to select targets equipped with IR receivers. The fundamental imprecision of head orientation requires a large selection beam \bjoern{term?} for successful target acquisition. However, a large beam area can lead to ambiguous selections. We introduce a two level disambiguation strategy: first, networked receivers use IR intensity sensors to estimate which target is the intended selection; second, users can fall back to a manual disambiguation technique using their near-eye display. The technique does not require an a priori map of target devices. However, a spatial data structure can be inferred to overcome sensor saturation problems in environments hostile to IR communication (e.g., in sunlight).
%
A target acquisition study with 14 participants shows that selection using head orientation with our device outperforms list selection on a wearable device. Intensity-based target disambiguation reduces selection time and error rate in dense target environments. We apply this technique to an application for controlling smart appliances and report qualitative usage data from a smart home scenario.
